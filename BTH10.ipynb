{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMIbQlPZtQKrqlqVLhievPu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0Tdy4LGBCERF","executionInfo":{"status":"ok","timestamp":1752481514865,"user_tz":-330,"elapsed":19,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}}},"outputs":[],"source":["#1. indroduction to Ai coding Assistant:------\n","\n","\n","# Ai coding assistants are tools powered by ML Model ( often uses LLms )that helps devloper to write,fix or understand the code\n","# they assist with code generation,debugging,documentation and many more\n","\n","# benefits:------\n","# 1. speed(acceleate development with code suggestion )\n","# 2.Productivity(Reduces Time spent Switching contrxt)\n","# 3.Accessbility(Assist beginner by explaining code)\n","\n","# Limitations:\n","# 1. suggest incorrect code\n","# 2. limited understanding of full project context\n","# 3. Risk of Overdependence for beginner (vibe coders)\n","\n","# example of platforms:\n","# 1. github copilot(suggest realtime in vs code using OpenAi codex)\n","# 2. Gemini code Assistant(Google Ai Assistant for code interated  with workspace and google cloud )\n","# 3. Amazon code whisper(AWS related code )\n","# 4.cursor(Ai first code Editor with powerful auto complete,Inline Chat and agent workflow)\n","# 5. tabnine(Privacy focused Ai code tool teams)\n","\n","# Demonstration and case Studies:\n","# Use Cases:\n","# 1. code Genration (Auto Generated functions and classes )\n","# 2. code completation(predict the next line of code )\n","# 3. Debugging (suggest bug fixes)\n","# 4. Auditing (IDentify security Issues)\n","# 5. Documentation (Generate Doc Strings and Readmes)\n","# 6. Agentic Workflows (multistep Ai Agent That Can Perform Complex Development task like finding a bug and fixing it, writing a test and pushing it to a repo automatically )"]},{"cell_type":"code","source":["!pip install -q gradio torchvision torch pillow\n","#gradio :- Build Gui for ml model/api,torch pytorch Deep Learning Networks,torchvision: pretrained Image model Like resent pillow :image Handling\n","\n","\n","#import required LIBs\n","import gradio as gr\n","from torchvision import models, transforms\n","from torchvision.models import ResNet50_Weights\n","from PIL import Image\n","import torch\n","import urllib.request\n","\n","#load pretarined resnet 50 and set to eval mode\n","model=models.resnet50(weights=ResNet50_Weights.DEFAULT)\n","model.eval()\n","\n","#load Imagene class labels\n","LABELS_URL=\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n","imagenet_classes=urllib.request.urlopen(LABELS_URL).read().decode(\"UTF-8\").splitlines()\n","\n","# step 5 Define Image Preprocessing pipeline\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","])\n","\n","\n","\n","#step 6 Define prediction function\n","def predict(img):\n","  if not isinstance(img, Image.Image):\n","    img=Image.fromarray(img)\n","  img = preprocess(img).unsqueeze(0)\n","  with torch.no_grad():\n","    output = model(img)\n","  _, index = output[0].max(0)\n","  label = imagenet_classes[index.item()]\n","  return f\"Predicted:{label}(class index:{index.item()})\"\n","\n","  # Lanuch Gradio App (GUI)\n","gr.Interface(fn=predict, inputs=gr.Image(type=\"pil\"),outputs=\"text\",title=\"AI Object Classifier(Imagenet)\").launch(share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"id":"Lx4JR-knCaqP","executionInfo":{"status":"ok","timestamp":1752482301971,"user_tz":-330,"elapsed":6781,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"1134e6cf-b32d-458c-c54a-5e7eb0161538"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://f90ca8c7b379c34f1a.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://f90ca8c7b379c34f1a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# Image Captioning\n","from transformers import BlipProcessor,  BlipForConditionalGeneration\n","from PIL import Image\n","import requests\n","import gradio as gr\n","import torch\n","processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n","model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n","def caption_image(image):\n","  inputs = processor(image,return_tensors=\"pt\")\n","  output = model.generate(**inputs)\n","  return processor.decode(output[0], skip_special_tokens=True)\n","gr.Interface(fn=caption_image, inputs=gr.Image(type=\"pil\"),outputs=\"text\",title=\"Image Captioning\").launch(share = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"id":"jH_0ETtEDmFO","executionInfo":{"status":"ok","timestamp":1752483142359,"user_tz":-330,"elapsed":5548,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"07ff4751-732a-4753-9194-03013facac7d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://7befde41843aae674c.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://7befde41843aae674c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":24}]}]}