{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPRBL3vvOmotE4kV8VrN+9N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"uA-CIN62KzfP","executionInfo":{"status":"ok","timestamp":1752050416510,"user_tz":-330,"elapsed":24,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"09332872-8a51-4ed6-b328-8e7bd93f99a1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n#Using LLM's for our application\\n\\n\\n#API = Application Programming Interface \\n--An API is a set of rules that allows different softwares application to communicate with each others.\\n--API works like a messanger between program , that let your program request information and send data to another server or service , which then respond with an result.\\n  -Ex=  Mobile App might use an API to get live weather information from a server.\\n\\n#Introduction to REST API:\\n                        #Representational State Transfer = It is a type of API that uses http method like GET , POST , UPDATE , DELETE to perform action on resources identified by the url.\\n#Key Concept:\\n              1. End Point = A specific url that perform a certain task. \\n                Ex:http//:google.com.\\n              2. Request  = The call made to the API.\\n                Ex: Including data or parameters.\\n              3. Response = The result the API send back usually in json format.\\n                Ex: JSON or XML data.\\n              4. Method = GET(Retrive), POST(Create) , PUT(Update) , DELETE(Remove)\\n            \\n\\n\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["'''\n","#Using LLM's for our application\n","\n","\n","#API = Application Programming Interface\n","--An API is a set of rules that allows different softwares application to communicate with each others.\n","--API works like a messanger between program , that let your program request information and send data to another server or service , which then respond with an result.\n","  -Ex=  Mobile App might use an API to get live weather information from a server.\n","\n","#Introduction to REST API:\n","                        #Representational State Transfer = It is a type of API that uses http method like GET , POST , UPDATE , DELETE to perform action on resources identified by the url.\n","#Key Concept:\n","              1. End Point = A specific url that perform a certain task.\n","                Ex:http//:google.com.\n","              2. Request  = The call made to the API.\n","                Ex: Including data or parameters.\n","              3. Response = The result the API send back usually in json format.\n","                Ex: JSON or XML data.\n","              4. Method = GET(Retrive), POST(Create) , PUT(Update) , DELETE(Remove)\n","\n","\n","\n","'''"]},{"cell_type":"code","source":["!pip install google-generativeai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tx6jcVMtV6I8","executionInfo":{"status":"ok","timestamp":1752051325137,"user_tz":-330,"elapsed":4662,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"5da1a6fa-2179-44d4-bec8-12e1730969fc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.174.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n","Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n","Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n","Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n","Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n"]}]},{"cell_type":"code","source":["'''\n","Import the python sdk\n","'''\n","import google.generativeai as genai\n","\n","#Used to securely store your API key\n","\n","from google.colab import userdata\n","GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n","\n","genai.configure(api_key=GOOGLE_API_KEY)\n"],"metadata":{"id":"6nxBy5FdXGga","executionInfo":{"status":"ok","timestamp":1752051907661,"user_tz":-330,"elapsed":638,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import google.generativeai as genai\n","for m in genai.list_models():\n","  if 'generateContent' in m.supported_generation_methods:\n","    print(m.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":781},"id":"phVkU-embnkb","executionInfo":{"status":"ok","timestamp":1752052454961,"user_tz":-330,"elapsed":2112,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"7028df41-27d6-4669-9562-cbea15b0a3cd"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["models/gemini-1.0-pro-vision-latest\n","models/gemini-pro-vision\n","models/gemini-1.5-pro-latest\n","models/gemini-1.5-pro-002\n","models/gemini-1.5-pro\n","models/gemini-1.5-flash-latest\n","models/gemini-1.5-flash\n","models/gemini-1.5-flash-002\n","models/gemini-1.5-flash-8b\n","models/gemini-1.5-flash-8b-001\n","models/gemini-1.5-flash-8b-latest\n","models/gemini-2.5-pro-preview-03-25\n","models/gemini-2.5-flash-preview-04-17\n","models/gemini-2.5-flash-preview-05-20\n","models/gemini-2.5-flash\n","models/gemini-2.5-flash-preview-04-17-thinking\n","models/gemini-2.5-flash-lite-preview-06-17\n","models/gemini-2.5-pro-preview-05-06\n","models/gemini-2.5-pro-preview-06-05\n","models/gemini-2.5-pro\n","models/gemini-2.0-flash-exp\n","models/gemini-2.0-flash\n","models/gemini-2.0-flash-001\n","models/gemini-2.0-flash-exp-image-generation\n","models/gemini-2.0-flash-lite-001\n","models/gemini-2.0-flash-lite\n","models/gemini-2.0-flash-preview-image-generation\n","models/gemini-2.0-flash-lite-preview-02-05\n","models/gemini-2.0-flash-lite-preview\n","models/gemini-2.0-pro-exp\n","models/gemini-2.0-pro-exp-02-05\n","models/gemini-exp-1206\n","models/gemini-2.0-flash-thinking-exp-01-21\n","models/gemini-2.0-flash-thinking-exp\n","models/gemini-2.0-flash-thinking-exp-1219\n","models/gemini-2.5-flash-preview-tts\n","models/gemini-2.5-pro-preview-tts\n","models/learnlm-2.0-flash-experimental\n","models/gemma-3-1b-it\n","models/gemma-3-4b-it\n","models/gemma-3-12b-it\n","models/gemma-3-27b-it\n","models/gemma-3n-e4b-it\n","models/gemma-3n-e2b-it\n"]}]},{"cell_type":"code","source":["import google.generativeai as genai\n","from google.colab import userdata\n","\n","#Configure with your key\n","#Access your api key from colab secrets\n","GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n","genai.configure(api_key=GOOGLE_API_KEY)\n","\n","#Load the model\n","model=genai.GenerativeModel(\"gemini-1.5-flash\")\n","\n","#send a prompt\n","response=model.generate_content(\"Explain gemini-1.5-flash like a scientist.\")\n","\n","# Print_the_result\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"QNNNuICjds07","executionInfo":{"status":"ok","timestamp":1752052859026,"user_tz":-330,"elapsed":5370,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"d3f06585-3579-492e-e1c2-ac42389cf0bc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Gemini-1.5-flash,  in the context of large language models (LLMs), represents a specific instantiation or a \"snapshot\" of the Gemini family of models developed by Google.  The \"1.5\" likely signifies an intermediate version between major releases (e.g., Gemini 1.0 and Gemini 2.0), indicating iterative improvements in architecture or training.  The \"flash\" designation suggests a model optimized for speed and low latency, prioritizing rapid inference over potentially higher accuracy or richer contextual understanding.\n","\n","From a scientific perspective, we can analyze Gemini-1.5-flash through several lenses:\n","\n","* **Architectural innovations:**  While the precise architecture isn't publicly available, we can infer that it likely employs a transformer-based architecture, common to most modern LLMs.  The \"flash\" optimization probably involves techniques to reduce computational complexity. This could include model quantization (reducing the precision of weights and activations), pruning (removing less important connections), knowledge distillation (training a smaller, faster student model on the output of a larger teacher model), or specialized hardware acceleration.\n","\n","* **Training data and methodology:** The model was trained on a massive dataset of text and code, representative of the internet's diverse information.  The training methodology likely involved techniques like self-supervised learning (learning from unlabeled data through tasks like predicting masked tokens) and potentially reinforcement learning from human feedback (RLHF) for alignment with human preferences. The \"flash\" aspect might imply a trade-off in the scale or diversity of the training data to prioritize inference speed.\n","\n","* **Performance metrics:**  Evaluating Gemini-1.5-flash would involve measuring its performance across various benchmarks, focusing not only on accuracy (e.g., BLEU score for translation, exact match for question answering) but crucially on latency (response time) and throughput (requests processed per second).  It's expected to show superior speed compared to its full-size counterpart (Gemini 1.0 or a similar model) while maintaining a reasonable level of accuracy.\n","\n","* **Limitations:**  The \"flash\" optimization inherently introduces a compromise. While improving speed, it might exhibit reduced performance on complex tasks requiring deeper understanding or more nuanced reasoning.  It might also be more susceptible to hallucinations or generating incorrect responses due to the simplified architecture or reduced training data.\n","\n","In summary, Gemini-1.5-flash represents a scientifically interesting case study in the optimization of LLMs for resource-constrained environments.  It highlights the ongoing research into balancing model capacity, accuracy, and speed, a crucial aspect for deploying these powerful models in real-world applications with limited computational budgets.  Further research would require access to its architecture, training data, and detailed performance evaluations to fully understand its scientific contribution.\n","\n"]}]},{"cell_type":"code","source":["import google.generativeai as genai\n","from google.colab import userdata\n","\n","#Configure with your key\n","#Access your api key from colab secrets\n","GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n","genai.configure(api_key=GOOGLE_API_KEY)\n","\n","#Load the model\n","model=genai.GenerativeModel(\"gemini-1.5-flash\")\n","\n","#send a prompt\n","response=model.generate_content(\"Explain about yourself.\")\n","\n","# Print_the_result\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"-87S_wFIfOrb","executionInfo":{"status":"ok","timestamp":1752054508697,"user_tz":-330,"elapsed":5295,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"e697f241-77f1-43df-e840-5999a87a4e5c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["I am a large language model, trained by Google.  I'm a computer program, not a person.  My purpose is to process information and respond to a wide range of prompts and questions in a comprehensive and informative way.  I don't have personal experiences, feelings, or opinions.\n","\n","My knowledge is based on the massive dataset I was trained on, which includes a vast amount of text and code.  This allows me to generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way, even if they are open ended, challenging, or strange.\n","\n","While I strive to be helpful and informative, it's important to remember that my responses are based on patterns and information from my training data.  I am still under development and may sometimes produce inaccurate or inappropriate information.  Therefore, it's always a good idea to verify important information from reliable sources.  I don't have access to real-time information, and my knowledge cutoff is a specific point in time.\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uMOfH5mZlhcu","executionInfo":{"status":"ok","timestamp":1752054549740,"user_tz":-330,"elapsed":5,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}}},"execution_count":23,"outputs":[]}]}